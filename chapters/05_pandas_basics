------------------------------------------------------
CHAPTER 05 - PANDAS BASICS
------------------------------------------------------

- NumPy vs pandas

    The biggest difference between NumPy and pandas is that pandas is designed for 
      working with tabular or heterogenous data, while Numpy is designed to work with 
      homogenous numerical array data.



- pandas Series

    >>> import pandas as pd
    >>> from pandas import Series, DataFrame


    A 'Series' is a 1D array-like object containing a sequence of values and an 
      associated array of data labels, called its 'index'.

    # The simplest series is just an array
    # The defualt index is integers 0 to N-1
    >>> obj = pd.Series([4, 7, -5, 3])
    >>> obj
    0    4
    1    7
    2    -5
    3    3

    >>> obj.index
    RangeIndex(start=0, stop=4, step=1)


    # Create a custom label for each data point
    >>> obj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])
    >>> obj2
    d    4
    b    7
    a    -5
    c    3

    >>> obj2.index
    Out[17]: Index(['d', 'b', 'a', 'c'], dtype='object')


    # The labels can be used as indexes
    >>> obj2['a']
    -5
    >>> obj2['d'] = 6

    >>> obj2[['c', 'a', 'd']]
    c    3
    a    -5
    d    6


    # The index-value link is preserved after Numpy or Numpy-like functions are applied
    >>> obj2[obj2 > 0]
    d    6
    b    7
    c    3

    >>> obj2 * 2
    d    12
    b    14
    a    -10
    c    6

    >>> np.exp(obj2)
    d     403.428793
    b    1096.633158
    a       0.006738
    c      20.085537



- Series as Dictionary-like Objects

    Another way to think of a Series is as a fixed-length, ordered dict.  It can be used
      like a dict in many contexts.

    >>> 'b' in obj2
    True

    >>> 'e' in obj2
    False


    # A series can be created from a dict
    # By default the index will put the dict's keys in sorted order
    >>> sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}
    >>> obj3 = pd.Series(sdata)
    >>> obj3 
    Ohio      35000
    Oregon    16000
    Texas     71000
    Utah       5000

    # If you want the keys in a different order, you can specify it in an array
    # Note that 'California' is set to NaN, since its not in the original data set
    >>> states = ['California', 'Ohio', 'Oregon', 'Texas']
    >>> obj4 = pd.Series(sdata, index=states)
    >>> obj4
    California        NaN
    Ohio          35000.0
    Oregon        16000.0
    Texas         71000.0


    # Both the series itself and its index have a name attribute
    >>> obj4.name = 'population'
    >>> obj4.index.name = 'state'
    >>> obj4
    state
    California        NaN
    Ohio          35000.0
    Oregon        16000.0
    Texas         71000.0
    Name: population, dtype: float64


    # Note that the index values can also be changed using in-place assignment
    >>> obj4.index = ['Ohio', 'Michigan', 'Indiana', 'Illinois']



- Checking for Missing Data in Series

    # The 'isnull' method checks for missing data
    >>> pd.isnull(obj4)
    California     True
    Ohio          False
    Oregon        False
    Texas         False
    dtype: bool

    # The instance method will return the same results
    >>> obj4.isnull()


    # The 'notnull' method checks for data that is present
    >>> pd.notnull(obj4)
    California    False
    Ohio           True
    Oregon         True
    Texas          True
    dtype: bool

    # There is an instance method for 'notnull' also
    >>> obj4.notnull()



- pandas DataFrames

    A DataFrame represents a rectangular table of data and contains an ordered
      colleciton of columns, each of which can be a different data type.


    # One of the most common ways to construct a DataSet is from a dict of
    #   equal length lists or NumPy arrays
    >>> data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],
                'year': [2000, 2001, 2002, 2001, 2002, 2003],
                'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}

    >>> frame = pd.DataFrame(data)


    # For large data frames, the 'head' method will select only the first 5 rows
    >>> frame.head()

    # If you specify a sequence of columns, the DataFrame's columns will be arranged
    #   in that order.  If you pass in a column that isn't contained in the dict, it will 
    #   appear with missing values in the result.
    >>> pd.DataFrame(data, columns=['year', 'state', 'pop'])



- Column and Row Access in DataFrames
    
    # Columns in the DataFrame can be retrieved as a Series by attribute
    >>> frame['state']
    >>> frame.state
    1     Ohio
    2     Ohio
    3     Ohio
    4     Nevada
    5     Nevada
    6     Nevada
    Name: state, dtype: object

    # Rows can be retrieved either by position or with the 'loc' attribute
    >>> frame.loc[3]
    year     2002
    state    Ohio
    pop       3.6
    debt      NaN
    Name: three, dtype: object


    # Assign an entire column with a value, assigning a column that doesn't exist
    #   will create a new column
    >>> frame['debt'] = 16.5

    # The 'del' keyword will delete an entire column, as with a dict
    >>> del frame['debt']



- Other Ways to Create DataFrames

    # Using a nested dict of dicts is a common way to create a DataSet.  By default, pandas
    #   will assume the outer dict is the columns and the inner dicts are the rows.
    >>> pop = {'Nevada': {2001: 2.4, 2002: 2.9},
               'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}
    >>> frame3 = pd.DataFrame(pop)
    >>> frame3
          Nevada  Ohio
    2000     NaN   1.5
    2001     2.4   1.7
    2002     2.9   3.6


    # To switch the rows and columns, just take the transpose
    >>> frame3.T
            2000  2001  2002
    Nevada   NaN   2.4   2.9
    Ohio     1.5   1.7   3.6


    # The index and columns have 'name' attributes which will also be displayed
    >>> frame3.index.name = 'Year'
    >>> frame3.columns.name = 'State'


    # The 'values' attributes returns the data contained in the DataFrame as a 2D ndarray
    >>> frame3.values
    array([[ nan,  1.5],
           [ 2.4,  1.7],
           [ 2.9,  3.6]])



- List of Possible Data Inputs to the DataFrame Constructor

    2D ndarray
    	A matrix of data, passing optional row and column labels
    
    dict of arrays, lists, or tuples
    	Each sequence becomes a column in the DataFrame; all sequences must be the same length
    
    NumPy structured/record array
    	Treated as the “dict of arrays” case
    
    dict of Series
    	Each value becomes a column; indexes from each Series are unioned together to form the 
    	  result’s row index if no explicit index is passed
    
    dict of dicts
    	Each inner dict becomes a column; keys are unioned to form the row index as in the 
    	  “dict of Series” case
    
    List of dicts or Series
    	Each item becomes a row in the DataFrame; union of dict keys or Series indexes become 
    	    the DataFrame’s column labels
    
    List of lists or tuples
    	Treated as the “2D ndarray” case
    
    Another DataFrame
    	The DataFrame’s indexes are used unless different ones are passed
    
    NumPy MaskedArray
    	Like the “2D ndarray” case except masked values become NA/missing in the DataFrame result



- Index Objects

    pandas's Index objects are responsible for holding the axis labels and other metadata.

    >>> obj = pd.Series(range(3), index=['a', 'b', 'c'])
    >>> obj.index
    Index(['a', 'b', 'c'], dtype='object')

    # Index objects are immutable
    >>> obj.index[1] = 'd'
    TypeError


    # Basic array operations can be used on indexes
    >>> frame3.columns
    Index(['Nevada', 'Ohio'], dtype='object', name='state')

    >>> 'Ohio' in frame3.columns
    True

    >>> 2003 in frame3.index
    False



- Reindexing Series

    The 'reindex' method is an important operation on pandas objects.

    # Create a Series
    >>> obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])
    >>> obj 
    d    4.5
    b    7.2
    a   -5.3
    c    3.6
    dtype: float64

    # Reindexing the Series rearranges the data according to the new index
    >>> obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])
    >>> obj2
    a   -5.3
    b    7.2
    c    3.6
    d    4.5
    e    NaN
    dtype: float64


    # You can also fill in values automatically when reindexing
    >>> obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])
    >>> obj3
    0      blue
    2    purple
    4    yellow
    dtype: object

    >>> obj3.reindex(range(6), method='ffill') 
    0      blue
    1      blue
    2    purple
    3    purple
    4    yellow
    5    yellow
    dtype: object



- Reindexing DataFrames

    With DataFrames, 'reindex' can alter the row index, the column index, or both.

    # Create a DataFrame
    >>> frame = pd.DataFrame(np.arange(9).reshape((3, 3)),
                             index=['a', 'c', 'd'],
                             columns=['Ohio', 'Texas', 'California'])
    >>> frame 

       Ohio  Texas  California
    a     0      1           2
    c     3      4           5
    d     6      7           8


    # By default, the 'reindex' method will reindex the rows
    >>> frame2 = frame.reindex(['a', 'b', 'c', 'd'])
    >>> frame2

       Ohio  Texas  California
    a   0.0    1.0         2.0
    b   NaN    NaN         NaN
    c   3.0    4.0         5.0
    d   6.0    7.0         8.0


    # The columns can be reindexed
    >>> states = ['Texas', 'Utah', 'California']
    >>> frame.reindex(columns=states)

       Texas  Utah  California
    a      1   NaN           2
    c      4   NaN           5
    d      7   NaN           8


    # Reindexing can be done more succinctly by label-indexing with 'loc'
    >>> frame.loc[['a', 'b', 'c', 'd'], states]

       Texas  Utah  California
    a    1.0   NaN         2.0
    b    NaN   NaN         NaN
    c    4.0   NaN         5.0
    d    7.0   NaN         8.0



- Dropping Entries from a Series

    The 'drop' method will return a new object with the indicated value or values deleted
      from an axis.  

    # Create a series
    >>> obj = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])
    >>> obj
 
    a    0.0
    b    1.0
    c    2.0
    d    3.0
    e    4.0
    dtype: float64

    # Drop rows from the series
    >>> new_obj = obj.drop(['d', 'c'])
    >>> new_obj

    a    0.0
    b    1.0
    e    4.0
    dtype: float64



- Dropping Entries from a DataFrame

    With DataFrames, index values can be deleted from either axis.

    # Create a DataFrame
    >>> data = pd.DataFrame(np.arange(16).reshape((4, 4)),
                            index=['Ohio', 'Colorado', 'Utah', 'New York'],
                            columns=['one', 'two', 'three', 'four'])
    >>> data
 
              one  two  three  four
    Ohio        0    1      2     3
    Colorado    4    5      6     7
    Utah        8    9     10    11
    New York   12   13     14    15

    # Calling 'drop' with a sequence of labels will drop values from the row labels
    >>> data.drop(['Colorado', 'Ohio'])

              one  two  three  four
    Utah        8    9     10    11
    New York   12   13     14    15

    # To drop values from columns, pass axis='columns'
    >>> data.drop(['two', 'four'], axis='columns')

              one  three
    Ohio        0      2
    Colorado    4      6
    Utah        8     10
    New York   12     14



- Indexing, Selection, and Filtering in Series

    >>> obj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])
    >>> obj
    a    0.0
    b    1.0
    c    2.0
    d    3.0
    dtype: float64

    >>> obj['b']
    1.0

    >>> obj[1]
    1.0

    >>> obj[2:4]
    c    2.0
    d    3.0
    dtype: float64

    >>> obj[['b', 'a', 'd']]
    b    1.0
    a    0.0
    d    3.0
    dtype: float64

    >>> obj[[1, 3]]
    b    1.0
    d    3.0
    dtype: float64

    >>> obj[obj < 2]
    a    0.0
    b    1.0
    dtype: float64


    # Note that when slicing with labels, the endpoint is inclusive
    >>> obj['b':'c']
    b    1.0
    c    2.0
    dtype: float64

    >>> obj['b':'c'] = 5
    >>> obj
    a    0.0
    b    5.0
    c    5.0
    d    3.0
    dtype: float64



- Indexing in DataFrames

    # Create a DataFrame
    >>> data = pd.DataFrame(np.arange(16).reshape((4, 4)),
                            index=['Ohio', 'Colorado', 'Utah', 'New York'],
                            columns=['one', 'two', 'three', 'four'])
    >>> data
 
              one  two  three  four
    Ohio        0    1      2     3
    Colorado    4    5      6     7
    Utah        8    9     10    11
    New York   12   13     14    15

    # Select a column
    >>> data['two']

    Ohio         1
    Colorado     5
    Utah         9
    New York    13
    Name: two, dtype: int64

    # Selects 2 columns
    >>> data[['three', 'one']]

              three  one
    Ohio          2    0
    Colorado      6    4
    Utah         10    8
    New York     14   12


    # Slicing to get a subset of rows
    >>> data[:2]

              one  two  three  four
    Ohio        0    1      2     3
    Colorado    4    5      6     7


    # Selecting rows with a boolean condition
    >>> data[data['three'] > 5]

              one  two  three  four
    Colorado    4    5      6     7
    Utah        8    9     10    11
    New York   12   13     14    15


    # Updating data with a boolean condition
    >>> data[data < 5] = 0
    >>> data

              one  two  three  four
    Ohio        0    0      0     0
    Colorado    0    5      6     7
    Utah        8    9     10    11
    New York   12   13     14    15



- Selection with 'loc' and 'iloc'

    The 'loc' and 'iloc' methods are special indexing operators which enable you to 
      select a subset of rows and columns using either axis labels (loc) or integers (iloc).

    # Select a single row and multiple columns by label
    >>> data.loc['Colorado', ['two', 'three']]

    two      5
    three    6
    Name: Colorado, dtype: int64    


    # Select a single row by integer
    >>> data.iloc[2]

    one       8
    two       9
    three    10
    four     11
    Name: Utah, dtype: int64

    # Select a single row with columns
    >>> data.iloc[2, [3, 0, 1]]

    four    11
    one      8
    two      9
    Name: Utah, dtype: int64

    # Multiple rows with multiple columns
    >>> data.iloc[[1, 2], [3, 0, 1]]

              four  one  two
    Colorado     7    0    5
    Utah        11    8    9

    # Indexing and slicing operations work also
    >>> data.loc[:'Utah', 'two']

    Ohio        0
    Colorado    5
    Utah        9
    Name: two, dtype: int64

    # Can also select using boolean conditions
    >>> data.iloc[:, :3][data.three > 5]
 
              one  two  three
    Colorado    0    5      6
    Utah        8    9     10
    New York   12   13     14



- List of DataFrame Indexing Operations

    Type                     Notes
    -------------------------------------------------------------------------------------------
    df[val]                     Select single column or sequence of columns from the DataFrame; 
                                  special case conveniences: boolean array (filter rows), slice 
                                  (slice rows), or boolean DataFrame (set values based on some 
                                  criterion)

    df.loc[val]                 Selects single row or subset of rows from the DataFrame by label

    df.loc[:, val]              Selects single column or subset of columns by label

    df.loc[val1, val2]          Select both rows and columns by label

    df.iloc[where]              Selects single row or subset of rows from the DataFrame by integer 
                                  position

    df.iloc[:, where]           Selects single column or subset of columns by integer position

    df.iloc[where_i, where_j]   Select both rows and columns by integer position

    df.at[label_i, label_j]     Select a single scalar value by row and column label

    df.iat[i, j]                Select a single scalar value by row and column position (integers)

    reindex method              Select either rows or columns by labels

    get_value, set_value        Select single value by row and column label



- Integer Indexes

    Note that there can be ambiguity if you have integer labels on a column that contains
      integers.  For this reason, there is a rule that if you have an axis index containing
      integers, data selection is always label-oriented.

    To make things a bit more explicit, using the 'loc' and 'iloc' methods in these cases
      is a best practice.

    # Create a series of integers
    >>> ser = pd.Series(np.arange(3.))
    >>> ser

    0    0.0
    1    1.0
    2    2.0
    dtype: float64


    # Integer index selects the first row by label
    >>> ser[:1]

    0    0.0
    dtype: float64


    # Select by label index
    >>> ser.loc[:1]

    0    0.0
    1    1.0
    dtype: float64


    # Select by integer index
    >>> ser.iloc[:1]
 
    0    0.0
    dtype: float64



- Arithmetic and Data Alignment in Series

    When arithmetic operations are performed on objects with different indexes, the result
      will be a union of the index pairs.  This is similar to a SQL OUTER JOIN.

    >>> s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])
    >>> s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'])

    >>> s1
    a    7.3
    c   -2.5
    d    3.4
    e    1.5
    dtype: float64

    >>> s2
    a   -2.1
    c    3.6
    e   -1.5
    f    4.0
    g    3.1
    dtype: float64

    # NaN values are inserted into labels that don't overlap
    >>> s1 + s2
    a    5.2
    c    1.1
    d    NaN
    e    0.0
    f    NaN
    g    NaN
    dtype: float64



- Arithmetic and Data Alignment in DataFrames

    With DataFrames, alignment is performed on both the rows and the columns.

    >>> df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'),
                           index=['Ohio', 'Texas', 'Colorado'])

    >>> df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'),
                           index=['Utah', 'Ohio', 'Texas', 'Oregon'])

    >>> df1

                b    c    d
    Ohio      0.0  1.0  2.0
    Texas     3.0  4.0  5.0
    Colorado  6.0  7.0  8.0

    >>> df2
 
              b     d     e
    Utah    0.0   1.0   2.0
    Ohio    3.0   4.0   5.0
    Texas   6.0   7.0   8.0
    Oregon  9.0  10.0  11.0


    # Adding the DataFrames returns a DataFrame whose index and columns are the unions
    #   of the ones in each DataFrame.
    >>> df1 + df2

                b   c     d   e
    Colorado  NaN NaN   NaN NaN
    Ohio      3.0 NaN   6.0 NaN
    Oregon    NaN NaN   NaN NaN
    Texas     9.0 NaN  12.0 NaN
    Utah      NaN NaN   NaN NaN



- Arithmetic Methods with Fill Values

    In arithmetic operations between differently indexed objects, you may just want to 
      fill all the NaN spaces with a special value like 0.

    # Add, while filling the NaN spaces with 0
    >>> df1.add(df2, fill_value=0)

    # Can also fill values when reindexing
    >>> df1.reindex(columns=df2.columns, fill_value=0)


    Here is a list of flexible arithmetic methods:

    Method                  Description
    ---------------------------------------------------------
    add, radd               Methods for addition (+)
    sub, rsub               Methods for subtraction (-)
    div, rdiv               Methods for division (/)
    floordiv, rfloordiv     Methods for floor division (//)
    mul, rmul               Methods for multiplication (*)
    pow, rpow               Methods for exponentiation (**)



- Operations Between DataFrames and Series

    Arithmetic operations between DataFrames and Series are supported.  By default,
      arithmetic between DataFrame and Series matches the index of the Series on the 
      DataFrame's columns, broadcasting down the rows.

    # Create a DataFrame and a Series
    >>> frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),
                             columns=list('bde'),
                             index=['Utah', 'Ohio', 'Texas', 'Oregon'])

    >>> series = frame.iloc[0]

    >>> frame
 
              b     d     e
    Utah    0.0   1.0   2.0
    Ohio    3.0   4.0   5.0
    Texas   6.0   7.0   8.0
    Oregon  9.0  10.0  11.0

    >>> series

    b    0.0
    d    1.0
    e    2.0
    Name: Utah, dtype: float64


    # By default, arithmetic between DataFrame and Series matches on the columns and
    #   broadcasts down the rows
    >>> frame - series

              b    d    e
    Utah    0.0  0.0  0.0
    Ohio    3.0  3.0  3.0
    Texas   6.0  6.0  6.0
    Oregon  9.0  9.0  9.0



- Function Application and Mapping

    # NumPy ufuncs also work with pandas objects
    >>> np.abs(frame)


    # 1D array functions can also be applied to each row of a DataFrame
    >>> f = lambda x: x.max() - x.min()
    >>> frame.apply(f)

    # 1D array functions can also be applied to columns
    >>> frame.apply(f, axis='columns')


    # Element-wise Python functions can be used too
    >>> format = lambda x: '%.2f' % x
    >>> frame.apply(format)



- Sorting

    # To sort lexicographically by row or column index, use the 'sort_index' method.
    #   This returns a new, sorted object.
    >>> obj = pd.Series(range(4), index=['d', 'a', 'b', 'c'])

    # Sort labels
    >>> obj.sort_index()

    a    1
    b    2
    c    3
    d    0
    dtype: int64

    # Sort values
    >>> obj.sort_values()

    d    0
    a    1
    b    2
    c    3
    dtype: int64


    # A DataFrame can be sorted on either axis
    >>> frame = pd.DataFrame(np.arange(8).reshape((2, 4)),
                             index=['three', 'one'],
                             columns=['d', 'a', 'b', 'c'])

    # Sort rows
    >>> frame.sort_index()

           d  a  b  c
    one    4  5  6  7
    three  0  1  2  3

    # Sort columns
    >>> frame.sort_index(axis=1)

           a  b  c  d
    three  1  2  3  0
    one    5  6  7  4


    # Sort descending instead of ascending
    >>> frame.sort_index(axis=1, ascending=False)

    # Sort on a given column or columns
    >>> frame.sort_values(by='b')
    >>> frame.sort_values(by=['a', 'b'])



- Ranking

    'Ranking' assigns ranks from 1-len(data) in an array.  By default, 'rank' breaks
      ties by assigning each tied group the mean rank.

    # Rank a series
    >>> obj = pd.Series([7, -5, 7, 4, 2, 0, 4])
    >>> obj.rank()

    0    6.5
    1    1.0
    2    6.5
    3    4.5
    4    3.0
    5    2.0
    6    4.5
    dtype: float64


    # DataFrames can compute rank over rows or columns.
    >>> frame = pd.DataFrame({'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1],
                              'c': [-2, 5, 8, -2.5]})

    # Rank columns
    >>> frame.rank(axis='columns')
         a    b    c
    0  2.0  3.0  1.0
    1  1.0  3.0  2.0
    2  2.0  1.0  3.0
    3  2.0  3.0  1.0


    This is a list of tie-breaking methods that can be used to rank:

    Method      Description
    ---------------------------------------------------------------------------------
    'average'   Default: assign the average rank to each entry in the equal group
    'min'       Use the minimum rank for the whole group
    'max'       Use the maximum rank for the whole group
    'first'     Assign ranks in the order the values appear in the data
    'dense'     Like method='min', but ranks always increase by 1 in between groups 
                  rather than the number of equal elements in a group



- Axis Indexes with Duplicate Labels

    While many pandas functions (ie 'reindex') require that labels be unique, it is not
      mandatory.

    # Create a series with duplicate labels
    >>> obj = pd.Series(range(5), index=['a', 'a', 'b', 'b', 'c'])
    >>> obj

    a    0
    a    1
    b    2
    b    3
    c    4
    dtype: int64


    # Indexing a duplicate label will return all matching rows
    >>> obj['a']

    a    0
    a    1
    dtype: int64


    # The 'is_unique' property will tell you whether your labels are unique
    >>> obj.index.is_unique
    False



- Summarizing and Computing Descriptive Statistics

    pandas objects are equipped with a set of common mathematical and statistical methods.
      Most of these are reductions or summary statistics.  They do handle missing data
      better than the corresponding NumPy methods in general.

    # Create a DataFrame
    >>> df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]],
                          index=['a', 'b', 'c', 'd'],
                          columns=['one', 'two'])
    >>> df

        one  two
    a  1.40  NaN
    b  7.10 -4.5
    c   NaN  NaN
    d  0.75 -1.3


    # The 'sum' method returns a Series containing column sums
    >>> df.sum()

    one    9.25
    two   -5.80
    dtype: float64

    # To sum the columns instead, the axis='columns' option is used
    >>> df.sum(axis='columns')

    a    1.40
    b    2.60
    c     NaN
    d   -0.55
    dtype: float64


    # Normally, the NaN columns are skipped, unless the 'skipna' flag is set to False
    >>> df.mean(axis='columns', skipna=False)


    # The 'describe' method will produce a set of summary statistics
    >>> df.describe()

                one       two
    count  3.000000  2.000000
    mean   3.083333 -2.900000
    std    3.493685  2.262742
    min    0.750000 -4.500000
    25%    1.075000 -3.700000
    50%    1.400000 -2.900000
    75%    4.250000 -2.100000
    max    7.100000 -1.300000



- List of Descriptive and Summary Statistics

    Method             Description
    -------------------------------------------------------------------------------------------------
    count              Number of non-NA values
    describe           Compute set of summary statistics for Series or each DataFrame column
    min, max           Compute minimum and maximum values
    argmin, argmax     Compute index locations (integers) at which minimum or maximum value obtained
    idxmin, idxmax     Compute index labels at which minimum or maximum value obtained, respectively
    quantile           Compute sample quantile ranging from 0 to 1
    sum                Sum of values
    mean               Mean of values
    median             Arithmetic median (50% quantile) of values
    mad                Mean absolute deviation from mean value
    prod               Product of all values
    var                Sample variance of values
    std                Sample standard deviation of values
    skew               Sample skewness (third moment) of values
    kurt               Sample kurtosis (fourth moment) of values
    cumsum             Cumulative sum of values
    cummin, cummax     Cumulative minimum or maximum of values, respectively
    cumprod            Cumulative product of values
    diff               Compute first arithmetic difference (useful for time series)
    pct_change         Compute percent changes



- Correlation and Covariance

    Some summary statistics, like correlation and covariance, are computed from pairs of
      arguments.  Here, we'll use some DataFrames of stock prices and volumes obtained
      from Yahoo Finance using the 'pandas-datareader' package.

    # Get the closing prices and trading volumes for a few stocks
    >>> import pandas_datareader.data as web

    >>> all_data = {ticker: web.get_data_yahoo(ticker)
                    for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']}

    >>> price = pd.DataFrame({ticker: data['Adj Close']
                              for ticker, data in all_data.items()})

    >>> volume = pd.DataFrame({ticker: data['Volume']
                               for ticker, data in all_data.items()})


    # Compute percent changes of the prices
    >>> returns = price.pct_change()
    >>> returns.tail()

                    AAPL       IBM      MSFT      GOOG
    Date                                              
    2019-03-21  0.036830  0.013180  0.022975  0.006185
    2019-03-22 -0.020708 -0.014070 -0.026368 -0.021144
    2019-03-25 -0.012091 -0.001936  0.005211 -0.010369
    2019-03-26 -0.010332  0.007472  0.002125 -0.007024
    2019-03-27  0.008994 -0.007132 -0.009668 -0.009792


    # Get the correlation between 2 series
    >>> returns['MSFT'].corr(returns['IBM'])
    0.4880920568696444

    # Get the covariance between 2 series
    >>> returns['MSFT'].cov(returns['IBM'])
    8.728436162356121e-05


    # The DataFrame's 'corr' and 'cov' methods return a full correlation or
    #   covariance matrix as a DataFrame
    >>> returns.corr()

              AAPL       IBM      MSFT      GOOG
    AAPL  1.000000  0.373384  0.451829  0.458214
    IBM   0.373384  1.000000  0.488092  0.408728
    MSFT  0.451829  0.488092  1.000000  0.537522
    GOOG  0.458214  0.408728  0.537522  1.000000

    >>> returns.cov()

              AAPL       IBM      MSFT      GOOG
    AAPL  0.000270  0.000076  0.000108  0.000116
    IBM   0.000076  0.000152  0.000087  0.000078
    MSFT  0.000108  0.000087  0.000210  0.000120
    GOOG  0.000116  0.000078  0.000120  0.000238


    # The DataFrame's 'corrwith' method lets you compute pairwise correlations between
    #   a DataFrame's columns or rows with another Series or DataFrame.
    #   (Note: 'returns.IBM' is legal, since 'IBM' is a valid Python identifier.)
    >>> returns.corrwith(returns.IBM)

    AAPL    0.373384
    IBM     1.000000
    MSFT    0.488092
    GOOG    0.408728
    dtype: float64

    # Correlate the percent changes with volume
    >>> returns.corrwith(volume)
    AAPL   -0.060785
    IBM    -0.152824
    MSFT   -0.089205
    GOOG   -0.017405
    dtype: float64



- Unique Values, Vaule Counts, and Membership

    # Get unique values in a series
    >>> s = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])
    >>> s.unique()
    array(['c', 'a', 'd', 'b'], dtype=object)


    # Get value counts for a series
    >>> pd.value_counts(s.values, sort=False)

    b    2
    a    3
    c    3
    d    1
    dtype: int64


    # The 'isin' method performs a vectorized set membership check
    >>> s[s.isin(['b', 'c'])]
    0    c
    5    b
    6    b
    7    c
    8    c
    dtype: object