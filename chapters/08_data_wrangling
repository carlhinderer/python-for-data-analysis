------------------------------------------------------
CHAPTER 08 - DATA WRANGLING
------------------------------------------------------

- Hierarchical Indexing

    'Hierarchical indexing' is an important feature of pandas that enables you to have
      2 or more index levels on an axis.  It provides a way to work with higher dimensional
      data in a lower dimensional form.


    # Create a series with a hierarchical index
    >>> data = pd.Series(np.random.randn(9),
                         index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],
                                [1, 2, 3, 1, 3, 1, 2, 2, 3]])
    >>> data
    a  1   -0.204708
       2    0.478943
       3   -0.519439
    b  1   -0.555730
       3    1.965781
    c  1    1.393406
       2    0.092908
    d  2    0.281746
       3    0.769023
    dtype: float64

    >>> data.index
    MultiIndex(levels=[['a', 'b', 'c', 'd'], [1, 2, 3]],
               labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 2, 0, 1, 1, 2]])


    # With a hierarchical indexed object, partial indexing can be used
    >>> data['b']
    1   -0.555730
    3    1.965781
    dtype: float64

    >>> data['b':'c'] 
    b  1   -0.555730
       3    1.965781
    c  1    1.393406
       2    0.092908
    dtype: float64

    >>> data.loc[['b', 'd']]
    b  1   -0.555730
       3    1.965781
    d  2    0.281746
       3    0.769023
    dtype: float64


    # Selection from an inner level is possible
    >>> data.loc[:, 2]
    a    0.478943
    c    0.092908
    d    0.281746
    dtype: float64



- Stacking and Unstacking

    Hierarchical indexing plays an important role in reshaping data and group-based operations
      like forming a pivot table.  


    # Unstacking into a flat DataFrame
    >>> data.unstack()

              1         2         3
    a -0.204708  0.478943 -0.519439
    b -0.555730       NaN  1.965781
    c  1.393406  0.092908       NaN
    d       NaN  0.281746  0.769023


    # Stacking is the opposite of unstacking
    >>> data.unstack().stack()

    a  1   -0.204708
       2    0.478943
       3   -0.519439
    b  1   -0.555730
       3    1.965781
    c  1    1.393406
       2    0.092908
    d  2    0.281746
       3    0.769023
    dtype: float64



- Column-Level Hierarchical Indexes

    # Either axis of a DataFrame can have a hierarchical index
    >>> frame = pd.DataFrame(np.arange(12).reshape((4, 3)),
                             index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],
                             columns=[['Ohio', 'Ohio', 'Colorado'],
                                      ['Green', 'Red', 'Green']])
    >>> frame
    
           Ohio     Colorado
        Green Red    Green
    a 1     0   1        2
      2     3   4        5
    b 1     6   7        8
      2     9  10       11


   # Select from hierarchical column
   >>> frame['Ohio']

    color      Green  Red
    key1 key2            
    a    1         0    1
         2         3    4
    b    1         6    7
         2         9   10



- Reordering and Sorting Levels

    At times, we will need to rearrange the order of the levels on the axis or sort the data
      by the values in one specific level.  The 'swaplevel' takes 2 level numbers or names
      and returns a new object with the levels interchanges.


    >>> frame.swaplevel('key1', 'key2')

    state      Ohio     Colorado
    color     Green Red    Green
    key2 key1                   
    1    a        0   1        2
    2    a        3   4        5
    1    b        6   7        8
    2    b        9  10       11


    The 'sort_index' method sorts the data using only the values in a single level.  When
      swapping levels, it's not uncommon to also use 'sort_index' so that the result is
      lexicographically sorted by the indicated level.


    # Sort on 'key2'
    >>> frame.sort_index(level=1)

    state      Ohio     Colorado
    color     Green Red    Green
    key1 key2                   
    a    1        0   1        2
    b    1        6   7        8
    a    2        3   4        5
    b    2        9  10       11
    

    >>> frame.swaplevel(0, 1).sort_index(level=0)
    Out[26]: 
    state      Ohio     Colorado
    color     Green Red    Green
    key2 key1                   
    1    a        0   1        2
         b        6   7        8
    2    a        3   4        5
         b        9  10       11



- Summary Statistics by Level

    Many of the DataFrame's descriptive and summary statistics have a 'level' option in 
      which you can specify the level you want to aggregate on a particular axis.


    # Aggregate rows
    >>> frame.sum(level='key2')

    state  Ohio     Colorado
    color Green Red    Green
    key2                    
    1         6   8       10
    2        12  14       16
    

    # Aggregate columns
    >>> frame.sum(level='color', axis=1)

    color      Green  Red
    key1 key2            
    a    1         2    1
         2         8    4
    b    1        14    7
         2        20   10



- Indexing With a DataFrame's Columns

    # Create a DataFrame
    >>> frame = pd.DataFrame({'a': range(7), 
                              'b': range(7, 0, -1),
                              'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'],
                              'd': [0, 1, 2, 0, 1, 2, 3]})
    >>> frame
 
       a  b    c  d
    0  0  7  one  0
    1  1  6  one  1
    2  2  5  one  2
    3  3  4  two  0
    4  4  3  two  1
    5  5  2  two  2
    6  6  1  two  3


    # Use 'set_index' to use columns as the index
    >>> frame2 = frame.set_index(['c', 'd'])
    >>> frame2

            a  b
    c    d      
    one  0  0  7
         1  1  6
         2  2  5
    two  0  3  4
         1  4  3
         2  5  2
         3  6  1


    # Use the columns as indexes, but keep the columns
    >>> frame.set_index(['c', 'd'], drop=False)

           a  b    c  d
    c   d              
    one 0  0  7  one  0
        1  1  6  one  1
        2  2  5  one  2
    two 0  3  4  two  0
        1  4  3  two  1
        2  5  2  two  2
        3  6  1  two  3
    
    
    # 'reset_index' does the opposite of 'set_index':
    >>> frame2.reset_index()
    
         c  d  a  b
    0  one  0  0  7
    1  one  1  1  6
    2  one  2  2  5
    3  two  0  3  4
    4  two  1  4  3
    5  two  2  5  2
    6  two  3  6  1



- Combining and Merging Datasets

    There are a number of different ways to combine pandas objects:

      1. 'pandas.merge' connects rows in DataFrames based on one or more keys, similarly
           to a SQL JOIN

      2. 'pandas.concat' concatenates (or 'stacks') objects together along an axis

      3. The 'combine_first' instance method enables splicing together overlapping data to
           fill in missing values in one object from another



- Database-Style DataFrame Joins

    Merge operations combine datasets by linking rows using one or more keys.


    # Create 2 DataFrames
    >>> df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],
                            'data1': range(7)})
    >>> df2 = pd.DataFrame({'key': ['a', 'b', 'd'],
                            'data2': range(3)})
    >>> df1
       data1 key
    0      0   b
    1      1   b
    2      2   a
    3      3   c
    4      4   a
    5      5   a
    6      6   b
    
    >>> df2
       data2 key
    0      0   a
    1      1   b
    2      2   d


    # Perform a many-to-one join, since df1 has multiple rows labeled 'a' and 'b',
    #   whereas df2 only has one row for each value in the 'key' column
    >>> pd.merge(df1, df2)

       data1 key  data2
    0      0   b      1
    1      1   b      1
    2      6   b      1
    3      2   a      0
    4      4   a      0
    5      5   a      0


    # Note that if the merge key is not specified, 'merge' uses the overlapping columns
    #   as keys (but it's a best practice to specify the key explicitly)
    >>> pd.merge(df1, df2, on='key')


    # If the column manes are different in each object, they can be specified separately
    >>> df3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],
                            'data1': range(7)})

    >>> df4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],
                            'data2': range(3)})

    >>> pd.merge(df3, df4, left_on='lkey', right_on='rkey')



- Outer Joins

    # Take the outer join
    >>> pd.merge(df1, df2, how='outer')

       data1 key  data2
    0    0.0   b    1.0
    1    1.0   b    1.0
    2    6.0   b    1.0
    3    2.0   a    0.0
    4    4.0   a    0.0
    5    5.0   a    0.0
    6    3.0   c    NaN
    7    NaN   d    2.0



- List of Different Join Types with the 'how' Argument

    Option	    Behavior
    -----------------------------------------------------------------------
    'inner'	    Use only the key combinations observed in both tables
    'left'	    Use all key combinations found in the left table
    'right'	    Use all key combinations found in the right table
    'outer'	    Use all key combinations observed in both tables together



- Many-to-Many Merges

    # Create DataSets
    >>> df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],
                            'data1': range(6)})

    >>> df2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],
                            'data2': range(5)})
    >>> df1
       data1 key
    0      0   b
    1      1   b
    2      2   a
    3      3   c
    4      4   a
    5      5   b
    
    >>> df2
       data2 key
    0      0   a
    1      1   b
    2      2   a
    3      3   b
    4      4   d


    # Many-to-many merge to get the Cartesian product
    >>> pd.merge(df1, df2, on='key', how='left')

        data1 key  data2
    0       0   b    1.0
    1       0   b    3.0
    2       1   b    1.0
    3       1   b    3.0
    4       2   a    0.0
    5       2   a    2.0
    6       3   c    NaN
    7       4   a    0.0
    8       4   a    2.0
    9       5   b    1.0
    10      5   b    3.0



- Merging with Multiple Keys

    >>> left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],
                             'key2': ['one', 'two', 'one'],
                             'lval': [1, 2, 3]})

    >>> right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],
                              'key2': ['one', 'one', 'one', 'two'],
                              'rval': [4, 5, 6, 7]})

    # Merge on composite key
    >>> pd.merge(left, right, on=['key1', 'key2'], how='outer')
 
      key1 key2  lval  rval
    0  foo  one   1.0   4.0
    1  foo  one   1.0   5.0
    2  foo  two   2.0   NaN
    3  bar  one   3.0   6.0
    4  bar  two   NaN   7.0


    # Merge also has the 'suffixes' option to specify strings to append to overlaping names
    >>> pd.merge(left, right, on='key1')

      key1 key2_x  lval key2_y  rval
    0  foo    one     1    one     4
    1  foo    one     1    one     5
    2  foo    two     2    one     4
    3  foo    two     2    one     5
    4  bar    one     3    one     6
    5  bar    one     3    two     7
    
    >>> pd.merge(left, right, on='key1', suffixes=('_left', '_right'))

      key1 key2_left  lval key2_right  rval
    0  foo       one     1        one     4
    1  foo       one     1        one     5
    2  foo       two     2        one     4
    3  foo       two     2        one     5
    4  bar       one     3        one     6
    5  bar       one     3        two     7



- List of Merge Function Arguments

    Argument	       Description
    ---------------------------------------------------------------------------------
    left	           DataFrame to be merged on the left side.

    right	           DataFrame to be merged on the right side.

    how	               One of 'inner', 'outer', 'left', or 'right'; defaults to 'inner'.

    on	               Column names to join on. Must be found in both DataFrame objects. If not 
                         specified and no other join keys given, will use the intersection of 
                         the column names in left and right as the join keys.

    left_on	           Columns in left DataFrame to use as join keys.

    right_on	       Analogous to left_on for left DataFrame.

    left_index	       Use row index in left as its join key (or keys, if a MultiIndex).

    right_index	       Analogous to left_index.

    sort	           Sort merged data lexicographically by join keys; True by default (disable 
                         to get better performance in some cases on large datasets).

    suffixes	       Tuple of string values to append to column names in case of overlap; 
                         defaults to ('_x', '_y') (e.g., if 'data' in both DataFrame objects, 
                         would appear as 'data_x' and 'data_y' in result).

    copy	           If False, avoid copying data into resulting data structure in some 
                         exceptional cases; by default always copies.

    indicator          Adds a special column _merge that indicates the source of each row; 
                         values will be 'left_only', 'right_only', or 'both' based on the origin 
                         of the joined data in each row.



- Merging on Index

    In some cases, the merge key in a DataFrame will be found in its index.  In this
      case, you can pass 'left_index=True' or 'right_index=True' (or both) to indicate
      that the index should be used as the merge key.


    # Create DataFrames
    >>> left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],
                              'value': range(6)})

    >>> right1 = pd.DataFrame({'group_val': [3.5, 7]}, 
                               index=['a', 'b'])
    >>> left1
      key  value
    0   a      0
    1   b      1
    2   a      2
    3   a      3
    4   b      4
    5   c      5
    
    >>> right1 
       group_val
    a        3.5
    b        7.0
    

    # Use the index as the merge key
    >>> pd.merge(left1, right1, left_on='key', right_index=True)
      key  value  group_val
    0   a      0        3.5
    2   a      2        3.5
    3   a      3        3.5
    1   b      1        7.0
    4   b      4        7.0


    # Form a union with an outer join instead
    >>> pd.merge(left1, right1, left_on='key', right_index=True, how='outer')
      key  value  group_val
    0   a      0        3.5
    2   a      2        3.5
    3   a      3        3.5
    1   b      1        7.0
    4   b      4        7.0
    5   c      5        NaN



- Merging on Hierarchical Indexes

    # Create DataFrames
    >>> lefth = pd.DataFrame({'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],
                              'key2': [2000, 2001, 2002, 2001, 2002],
                              'data': np.arange(5.)})

    >>> righth = pd.DataFrame(np.arange(12).reshape((6, 2)),
                             index=[['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'],
                                    [2001, 2000, 2000, 2000, 2001, 2002]],
                             columns=['event1', 'event2'])
    >>> lefth
       data    key1  key2
    0   0.0    Ohio  2000
    1   1.0    Ohio  2001
    2   2.0    Ohio  2002
    3   3.0  Nevada  2001
    4   4.0  Nevada  2002
    
    >>> righth
                 event1  event2
    Nevada 2001       0       1
           2000       2       3
    Ohio   2000       4       5
           2000       6       7
           2001       8       9
           2002      10      11
    

    # Indicate multiple columns to merge on as a list 
    >>> pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True)

       data    key1  key2  event1  event2
    0   0.0    Ohio  2000       4       5
    0   0.0    Ohio  2000       6       7
    1   1.0    Ohio  2001       8       9
    2   2.0    Ohio  2002      10      11
    3   3.0  Nevada  2001       0       1
    

    # Handle duplicate index values with how='outer'
    >>> pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True, how='outer')

       data    key1  key2  event1  event2
    0   0.0    Ohio  2000     4.0     5.0
    0   0.0    Ohio  2000     6.0     7.0
    1   1.0    Ohio  2001     8.0     9.0
    2   2.0    Ohio  2002    10.0    11.0
    3   3.0  Nevada  2001     0.0     1.0
    4   4.0  Nevada  2002     NaN     NaN
    4   NaN  Nevada  2000     2.0     3.0



- Merging on Both Sides of a Hierarchical Index

    # Create the DataFrames
    >>> left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],
                             index=['a', 'c', 'e'],
                             columns=['Ohio', 'Nevada'])

    >>> right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],
                              index=['b', 'c', 'd', 'e'],
                              columns=['Missouri', 'Alabama'])
    >>> left2
       Ohio  Nevada
    a   1.0     2.0
    c   3.0     4.0
    e   5.0     6.0
    
    >>> right2
       Missouri  Alabama
    b       7.0      8.0
    c       9.0     10.0
    d      11.0     12.0
    e      13.0     14.0

    
    >>> pd.merge(left2, right2, how='outer', left_index=True, right_index=True)

       Ohio  Nevada  Missouri  Alabama
    a   1.0     2.0       NaN      NaN
    b   NaN     NaN       7.0      8.0
    c   3.0     4.0       9.0     10.0
    d   NaN     NaN      11.0     12.0
    e   5.0     6.0      13.0     14.0



- The 'join' Instance Method

    The 'join' instance method (left over from the early days of pandas) performs a
      left join on the join keys, exactly preserving the left frame's row index.

    >>> left1.join(right1, on='key')
 
      key  value  group_val
    0   a      0        3.5
    1   b      1        7.0
    2   a      2        3.5
    3   a      3        3.5
    4   b      4        7.0
    5   c      5        NaN



- Concatenating Along An Axis

    Concatenating (aka 'binding' or 'stacking') is another popular type of data combination.

    # Numpy array concatentation
    >>> arr = np.arange(12).reshape((3, 4))
    >>> arr
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11]])
    
    In [81]: np.concatenate([arr, arr], axis=1)
    array([[ 0,  1,  2,  3,  0,  1,  2,  3],
           [ 4,  5,  6,  7,  4,  5,  6,  7],
           [ 8,  9, 10, 11,  8,  9, 10, 11]])


    When concatenating pandas objects, there are a few additional things to consider.

      1. If the objects are indexed differently, should we combine the distinct elements
           or only the intersection?

      2. Do the concatenated chunks of data need to be identifiable in the resulting object?

      3. Does the concatenation axis contain data that needs to be preserved?  Or should
           we just discard the default integer labels?



- The Series 'concat' Function

    # Suppose we have 3 Series with no index overlap
    >>> s1 = pd.Series([0, 1], index=['a', 'b'])
    >>> s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])
    >>> s3 = pd.Series([5, 6], index=['f', 'g'])

    # Calling 'concat' with these objects in a list glues together the values and indexes
    >>> pd.concat([s1, s2, s3])

    a    0
    b    1
    c    2
    d    3
    e    4
    f    5
    g    6
    dtype: int64


    # By default, 'concat' works with 'axis=0', producing another Series.
    # If we pass 'axis=1' instead, the result will be a DataFrame instead.
    >>> pd.concat([s1, s2, s3], axis=1)

         0    1    2
    a  0.0  NaN  NaN
    b  1.0  NaN  NaN
    c  NaN  2.0  NaN
    d  NaN  3.0  NaN
    e  NaN  4.0  NaN
    f  NaN  NaN  5.0
    g  NaN  NaN  6.0


    # By default, the column concatenation will produce the outer join of the indexes.
    # To intersect them instead, can pass join='inner'.
    >>> pd.concat([s1, s3])

    a    0
    b    1
    f    5
    g    6
    dtype: int64
    
    >>> pd.concat([s1, s4], axis=1)

         0  1
    a  0.0  0
    b  1.0  1
    f  NaN  5
    g  NaN  6
    
    >>> pd.concat([s1, s4], axis=1, join='inner')

       0  1
    a  0  0
    b  1  1



- Special Cases When Concatenating Series

    # Specify the axes to be used on the other axes with the 'join_axes' argument
    >>> pd.concat([s1, s4], axis=1, join_axes=[['a', 'c', 'b', 'e']])

         0    1
    a  0.0  0.0
    c  NaN  NaN
    b  1.0  1.0
    e  NaN  NaN


    # Create a hierarchical index on the concatenation axis with the 'keys' argument
    >>> result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])
    >>> result
 
    one    a    0
           b    1
    two    a    0
           b    1
    three  f    5
           g    6
    dtype: int64
    
    >>> result.unstack()

             a    b    f    g
    one    0.0  1.0  NaN  NaN
    two    0.0  1.0  NaN  NaN
    three  NaN  NaN  5.0  6.0


    # When concatenating along the column axis, the 'keys' become DataFrame column headers
    >>> pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three'])

       one  two  three
    a  0.0  NaN    NaN
    b  1.0  NaN    NaN
    c  NaN  2.0    NaN
    d  NaN  3.0    NaN
    e  NaN  4.0    NaN
    f  NaN  NaN    5.0
    g  NaN  NaN    6.0



- Concatenating DataFrames

    >>> df1 = pd.DataFrame(np.arange(6).reshape(3, 2), 
                           index=['a', 'b', 'c'],
                           columns=['one', 'two'])

    >>> df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), 
                           index=['a', 'c'],
                           columns=['three', 'four'])
    >>> df1
       one  two
    a    0    1
    b    2    3
    c    4    5

    >>> df2 
       three  four
    a      5     6
    c      7     8


    # Concatenating DataFrames
    >>> pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])

      level1     level2     
         one two  three four
    a      0   1    5.0  6.0
    b      2   3    NaN  NaN
    c      4   5    7.0  8.0


    # If a dict of objects is passed in instead of a list, the dict's keys will be used
    #   for the 'keys' option
    >>> pd.concat({'level1': df1, 'level2': df2}, axis=1)

      level1     level2     
         one two  three four
    a      0   1    5.0  6.0
    b      2   3    NaN  NaN
    c      4   5    7.0  8.0


    # And we can name the axis levels with the 'names' argument
    >>> pd.concat([df1, df2], 
                  axis=1, 
                  keys=['level1', 'level2'],
                 names=['upper', 'lower'])

    upper level1     level2     
    lower    one two  three four
    a          0   1    5.0  6.0
    b          2   3    NaN  NaN
    c          4   5    7.0  8.0



- List of 'concat' Function Arguments

    Argument	    Description
    ----------------------------------------------------------------------------------
    objs	        List or dict of pandas objects to be concatenated; this is the only 
                      required argument

    axis	        Axis to concatenate along; defaults to 0 (along rows)

    join	        Either 'inner' or 'outer' ('outer' by default); whether to intersection 
                      (inner) or union (outer) together indexes along the other axes

    join_axes	    Specific indexes to use for the other nâ€“1 axes instead of performing 
                      union/intersection logic

    keys	        Values to associate with objects being concatenated, forming a hierarchical 
                      index along the concatenation axis; can either be a list or array of 
                      arbitrary values, an array of tuples, or a list of arrays (if 
                      multiple-level arrays passed in levels)

    levels	        Specific indexes to use as hierarchical index level or levels if keys passed

    names	        Names for created hierarchical levels if keys and/or levels passed

    verify_integrity  Check new axis in concatenated object for duplicates and raise exception 
                        if so; by default (False) allows duplicates

    ignore_index	Do not preserve indexes along concatenation axis, instead producing a 
                       new range(total_length) index



- Combining Data With Overlap

    There is another data combination situation that can't be expressed as either a merge or
      concatenation operation.  You may have 2 datasets whose indexes overlap in full or in
      part:

    >>> a = pd.Series([np.nan, 2.5, 0.0, 3.5, 4.5, np.nan],
                      index=['f', 'e', 'd', 'c', 'b', 'a'])

    >>> b = pd.Series([0., np.nan, 2., np.nan, np.nan, 5.],
                      index=['a', 'b', 'c', 'd', 'e', 'f'])

    >>> a

    f    NaN
    e    2.5
    d    0.0
    c    3.5
    b    4.5
    a    NaN
    dtype: float64
    
    >>> b

    a    0.0
    b    NaN
    c    2.0
    d    NaN
    e    NaN
    f    5.0
    dtype: float64
    
    >>> np.where(pd.isnull(a), b, a)
    array([ 0. ,  2.5,  0. ,  3.5,  4.5,  5. ])


    # Series has a 'combine_first' method, which performs the equivalent of this operation
    #   along with pandas's usual data alignment logic
    >>> b.combine_first(a)

    a    0.0
    b    4.5
    c    2.0
    d    0.0
    e    2.5
    f    5.0
    dtype: float64


    # DataFrame's 'combine_first' does the same thing column-by-column.  Basically, it 'patches'
    #   the missing data from the calling object with data from the object passed in.
    >>> df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan],
                            'b': [np.nan, 2., np.nan, 6.],
                            'c': range(2, 18, 4)})

    >>> df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.],
                            'b': [np.nan, 3., 4., 6., 8.]})
    
    >>> df1
 
         a    b   c
    0  1.0  NaN   2
    1  NaN  2.0   6
    2  5.0  NaN  10
    3  NaN  6.0  14
    
    >>> df2
    
         a    b
    0  5.0  NaN
    1  4.0  3.0
    2  NaN  4.0
    3  3.0  6.0
    4  7.0  8.0
    
    >>> df1.combine_first(df2)
    
         a    b     c
    0  1.0  NaN   2.0
    1  4.0  2.0   6.0
    2  5.0  4.0  10.0
    3  3.0  6.0  14.0
    4  7.0  8.0   NaN



- Reshaping With Hierarchical Indexing

    Hierarchical indexing provides a consistent way to rearrange data in a DataFrame.
      There are 2 primary actions:

      1. 'stack' = rotates (or 'pivots') from the columns in the data to the rows

      2. 'unstack' = pivots from the rows to the columns


    # Consider a small DataFrame with string arrays as row and column indexes
    data = pd.DataFrame(np.arange(6).reshape((2, 3)),
                        index=pd.Index(['Ohio', 'Colorado'], name='state'),
                        columns=pd.Index(['one', 'two', 'three'], name='number'))

    >>> data

    number    one  two  three
    state                    
    Ohio        0    1      2
    Colorado    3    4      5


    # Using the 'stack' method on this data pivots the columns into the rows, 
    #   producing a Series
    >>> result = data.stack()
    >>> result

    state     number
    Ohio      one       0
              two       1
              three     2
    Colorado  one       3
              two       4
              three     5
    dtype: int64


    # From a hierarchically indexed Series, you can rearrange the data back into a 
    #   DataFrame with 'unstack'
    >>> result.unstack()

    number    one  two  three
    state                    
    Ohio        0    1      2
    Colorado    3    4      5    



- Stacking and Unstacking By Level

    By default, the innermost level is unstacked (same with 'stack').  You can unstack
      a different level by passing a level number or name.

    # Unstack by a given level number
    >>> result.unstack(0)

    state   Ohio  Colorado
    number                
    one        0         3
    two        1         4
    three      2         5


    # Unstack by a given level name
    >>> result.unstack('state')
    state   Ohio  Colorado
    number                
    one        0         3
    two        1         4
    three      2         5



- Handling Missing Data When Stacking and Unstacking

    Unstacking may introduce missing data if all of the values in the level aren't found
      in each of the subgroups.

    # Create the stacked data
    >>> s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])
    >>> s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e'])
    >>> data2 = pd.concat([s1, s2], keys=['one', 'two'])
    >>> data2
 
    one  a    0
         b    1
         c    2
         d    3
    two  c    4
         d    5
         e    6
    dtype: int64
    
    
    >>> data2.unstack()
     
           a    b    c    d    e
    one  0.0  1.0  2.0  3.0  NaN
    two  NaN  NaN  4.0  5.0  6.0


    Stacking filters out missing data by default, so the operation is more easily invertible.

    >>> data2.unstack().stack()

    one  a    0.0
         b    1.0
         c    2.0
         d    3.0
    two  c    4.0
         d    5.0
         e    6.0
    dtype: float64
    

    To keep missing data, use 'dropna=False'.

    >>> data2.unstack().stack(dropna=False)
    
    one  a    0.0
         b    1.0
         c    2.0
         d    3.0
         e    NaN
    two  a    NaN
         b    NaN
         c    4.0
         d    5.0
         e    6.0
    dtype: float64



- Specifying the Stack Index

    When you unstack a DataFrame, the level unstacked becomes the lowest level in the 
      result.

    >>> df = pd.DataFrame({'left': result, 'right': result + 5},
                           columns=pd.Index(['left', 'right'], name='side'))
    >>> df
 
    side             left  right
    state    number             
    Ohio     one        0      5
             two        1      6
             three      2      7
    Colorado one        3      8
             two        4      9
             three      5     10
    

    >>> df.unstack('state')
    
    side   left          right         
    state  Ohio Colorado  Ohio Colorado
    number                             
    one       0        3     5        8
    two       1        4     6        9
    three     2        5     7       10


    When calling 'stack', we can indicate the name of the axis to stack.

    >>> df.unstack('state').stack('side')
 
    state         Colorado  Ohio
    number side                 
    one    left          3     0
           right         8     5
    two    left          4     1
           right         9     6
    three  left          5     2
           right        10     7



- Long Format (aka Stacked Format)

    A common way to store multiple time series in databases and CSV files is in 
      'long format' (aka 'stacked format').  


    # Here, we load some sample data, and do a small amount of time series wrangling
    #   and other data cleaning.
    >>> data = pd.read_csv('examples/macrodata.csv')
    >>> data.head()

         year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi  \
    0  1959.0      1.0  2710.349    1707.4  286.898   470.045   1886.9  28.98   
    1  1959.0      2.0  2778.801    1733.7  310.859   481.301   1919.7  29.15   
    2  1959.0      3.0  2775.488    1751.8  289.226   491.260   1916.4  29.35   
    3  1959.0      4.0  2785.204    1753.7  299.356   484.052   1931.3  29.37   
    4  1960.0      1.0  2847.699    1770.5  331.722   462.199   1955.5  29.54   

          m1  tbilrate  unemp      pop  infl  realint  
    0  139.7      2.82    5.8  177.146  0.00     0.00  
    1  141.7      3.08    5.1  177.830  2.34     0.74  
    2  140.5      3.82    5.3  178.657  2.74     1.09  
    3  140.0      4.33    5.6  179.386  0.27     4.06  
    4  139.6      3.50    5.2  180.007  2.31     1.19  


    >>> periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')
    >>> columns = pd.Index(['realgdp', 'infl', 'unemp'], name='item')
    >>> data = data.reindex(columns=columns)
    >>> data.index = periods.to_timestamp('D', 'end')
    >>> ldata = data.stack().reset_index().rename(columns={0: 'value'})


    # This current value of 'ldata' is in 'long format' for multiple time series.
    >>> ldata[:10]

            date     item     value
    0 1959-03-31  realgdp  2710.349
    1 1959-03-31     infl     0.000
    2 1959-03-31    unemp     5.800
    3 1959-06-30  realgdp  2778.801
    4 1959-06-30     infl     2.340
    5 1959-06-30    unemp     5.100
    6 1959-09-30  realgdp  2775.488
    7 1959-09-30     infl     2.740
    8 1959-09-30    unemp     5.300
    9 1959-12-31  realgdp  2785.204



- Pivoting 'Long' to 'Wide' Format

    Data is frequently stored in long format in relational databases.  To make it easy
      to work with, it's often easier to convert back into a DataFrame after pulling it
      out of the database.  The DataFrame's 'pivot' method does this transformation.


    # The parameters are (row_index, column_index, column_to_fill_dataframe)
    >>> pivoted = ldata.pivot('date', 'item', 'value')
    >>> pivoted[:10]

    item        infl    realgdp  unemp
    date                              
    1959-03-31  0.00   2710.349    5.8
    1959-06-30  2.34   2778.801    5.1
    1959-09-30  2.74   2775.488    5.3
    1959-12-31  0.27   2785.204    5.6
    1960-03-31  2.31   2847.699    5.2
    1960-06-30  0.14   2834.390    5.2
    1960-09-30  2.70   2839.022    5.6
    1960-12-31  1.21   2802.616    6.3
    1961-03-31 -0.40   2819.264    6.8
    1961-06-30  1.47   2872.005    7.0


    # If you have 2 columns that you want to reshape at the same time, you can omit
    #   the 3rd parameter to obtain a DataFrame with hierarchical columns.
    >>> ldata['value2'] = np.random.randn(len(ldata))
    >>> ldata[:10]

            date     item     value    value2
    0 1959-03-31  realgdp  2710.349  0.523772
    1 1959-03-31     infl     0.000  0.000940
    2 1959-03-31    unemp     5.800  1.343810
    3 1959-06-30  realgdp  2778.801 -0.713544
    4 1959-06-30     infl     2.340 -0.831154
    5 1959-06-30    unemp     5.100 -2.370232
    6 1959-09-30  realgdp  2775.488 -1.860761
    7 1959-09-30     infl     2.740 -0.860757
    8 1959-09-30    unemp     5.300  0.560145
    9 1959-12-31  realgdp  2785.204 -1.265934 


    >>> pivoted = ldata.pivot('date', 'item')
    >>> pivoted[:5]

               value                    value2                    
    item        infl   realgdp unemp      infl   realgdp     unemp
    date                                                          
    1959-03-31  0.00  2710.349   5.8  0.000940  0.523772  1.343810
    1959-06-30  2.34  2778.801   5.1 -0.831154 -0.713544 -2.370232
    1959-09-30  2.74  2775.488   5.3 -0.860757 -1.860761  0.560145
    1959-12-31  0.27  2785.204   5.6  0.119827 -1.265934 -1.063512
    1960-03-31  2.31  2847.699   5.2 -2.359419  0.332883 -0.199543
    
    >>> pivoted['value'][:5]

    item        infl   realgdp  unemp
    date                             
    1959-03-31  0.00  2710.349    5.8
    1959-06-30  2.34  2778.801    5.1
    1959-09-30  2.74  2775.488    5.3
    1959-12-31  0.27  2785.204    5.6
    1960-03-31  2.31  2847.699    5.2



- Pivoting vs Unstacking

    Note that 'pivot' is equivalent to creating a hierarchical index using 'set_index'
      followed by a call to 'unstack'.


    >>> unstacked = ldata.set_index(['date', 'item']).unstack('item')
    >>> unstacked[:7]
    
               value                    value2                    
    item        infl   realgdp unemp      infl   realgdp     unemp
    date                                                          
    1959-03-31  0.00  2710.349   5.8  0.000940  0.523772  1.343810
    1959-06-30  2.34  2778.801   5.1 -0.831154 -0.713544 -2.370232
    1959-09-30  2.74  2775.488   5.3 -0.860757 -1.860761  0.560145
    1959-12-31  0.27  2785.204   5.6  0.119827 -1.265934 -1.063512
    1960-03-31  2.31  2847.699   5.2 -2.359419  0.332883 -0.199543
    1960-06-30  0.14  2834.390   5.2 -0.970736 -1.541996 -1.307030
    1960-09-30  2.70  2839.022   5.6  0.377984  0.286350 -0.753887



- Pivoting 'Wide' to 'Long' Format

    The inverse operation to 'pivot' for DataFrames is 'pandas.melt'.  Rather than 
      transforming one column into many in a new DataFrame, it merges multiple columns
      into one, producing a DataFrame that is longer than the input.


    # Create a DataFrame
    >>> df = pd.DataFrame({'key': ['foo', 'bar', 'baz'],
                           'A': [1, 2, 3],
                           'B': [4, 5, 6],
                           'C': [7, 8, 9]})
    >>> df

       A  B  C  key
    0  1  4  7  foo
    1  2  5  8  bar
    2  3  6  9  baz


    # When using 'pandas.melt', we indicate which columns are group indicators
    >>> melted = pd.melt(df, ['key'])
    >>> melted

       key variable  value
    0  foo        A      1
    1  bar        A      2
    2  baz        A      3
    3  foo        B      4
    4  bar        B      5
    5  baz        B      6
    6  foo        C      7
    7  bar        C      8
    8  baz        C      9


    # Then, we can reshape it back to the original layout with 'pivot'
    >>> reshaped = melted.pivot('key', 'variable', 'value')
    >>> reshaped

    variable  A  B  C
    key              
    bar       2  5  8
    baz       3  6  9
    foo       1  4  7



- Advanced Melting

    # Since the result of 'pivot' creates an index from the column used as the row labels,
    #   we can use 'reset_index' to move the data back into a column.
    >>> reshaped.reset_index()

    variable  key  A  B  C
    0         bar  2  5  8
    1         baz  3  6  9
    2         foo  1  4  7


    # You can also specify a subset of columns to use as value columns
    >>> pd.melt(df, id_vars=['key'], value_vars=['A', 'B'])

       key variable  value
    0  foo        A      1
    1  bar        A      2
    2  baz        A      3
    3  foo        B      4
    4  bar        B      5
    5  baz        B      6
    

    # pandas.melt can be used without any group identifiers, too:
    >>> pd.melt(df, value_vars=['A', 'B', 'C'])

      variable  value
    0        A      1
    1        A      2
    2        A      3
    3        B      4
    4        B      5
    5        B      6
    6        C      7
    7        C      8
    8        C      9
    
    >>> pd.melt(df, value_vars=['key', 'A', 'B'])

      variable value
    0      key   foo
    1      key   bar
    2      key   baz
    3        A     1
    4        A     2
    5        A     3
    6        B     4
    7        B     5
    8        B     6    