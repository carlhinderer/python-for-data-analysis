------------------------------------------------------
CHAPTER 06 - DATA LOADING AND STORAGE
------------------------------------------------------

- Parsing Functions in pandas

    Function	     Description
    --------------------------------------------------------------------------------------
    read_csv	     Load delimited data from a file, URL, or file-like object; use comma 
                       as default delimiter

    read_table	     Load delimited data from a file, URL, or file-like object; use tab ('\t') 
                       as default delimiter

    read_fwf	     Read data in fixed-width column format (i.e., no delimiters)

    read_clipboard	 Version of read_table that reads data from the clipboard; useful for 
                       converting tables from web pages

    read_excel	     Read tabular data from an Excel XLS or XLSX file

    read_hdf	     Read HDF5 files written by pandas

    read_html	     Read all tables found in the given HTML document

    read_json	     Read data from a JSON (JavaScript Object Notation) string representation

    read_msgpack	 Read pandas data encoded using the MessagePack binary format

    read_pickle	     Read an arbitrary object stored in Python pickle format

    read_sas	     Read a SAS dataset stored in one of the SAS systemâ€™s custom storage formats

    read_sql	     Read the results of a SQL query (using SQLAlchemy) as a pandas DataFrame

    read_stata	     Read a dataset from Stata file format

    read_feather	 Read the Feather binary file format



- Reading from CSV

    # Here we have a sample csv
    >>> !cat examples/ex1.csv

    a,b,c,d,message
    1,2,3,4,hello
    5,6,7,8,world
    9,10,11,12,foo


    # Here we read the csv into a DataFrame
    >>> df = pd.read_csv('examples/ex1.csv')
    >>> df

       a   b   c   d message
    0  1   2   3   4   hello
    1  5   6   7   8   world
    2  9  10  11  12     foo


    # Or, we can use 'read_table' and specify the delimiter, which will give
    #   us the same DataFrame
    >>> pd.read_table('examples/ex1.csv', sep=',')


    # Sometimes files don't have a header row
    >>> !cat examples/ex2.csv

    1,2,3,4,hello
    5,6,7,8,world
    9,10,11,12,foo

    # In this case, you can either let pandas assign default column names
    >>> pd.read_csv('examples/ex2.csv', header=None)

       0   1   2   3      4
    0  1   2   3   4  hello
    1  5   6   7   8  world
    2  9  10  11  12    foo

    # Or you can specify the column names yourself
    >>> pd.read_csv('examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])



- Specifying Index and Columns

    # You can specify that one of the columns should be the index
    >>> names = ['a', 'b', 'c', 'd', 'e']
    >>> pd.read_csv('examples/ex2.csv', names=names, index_col='message')

             a   b   c   d
    message               
    hello    1   2   3   4
    world    5   6   7   8
    foo      9  10  11  12


    # A list of column names can be passed to form a hierarchical index of multiple columns
    >>> !cat examples/csv_mindex.csv

    key1,key2,value1,value2
    one,a,1,2
    one,b,3,4
    one,c,5,6
    one,d,7,8
    two,a,9,10
    two,b,11,12
    two,c,13,14
    two,d,15,16

    >>> parsed = pd.read_csv('examples/csv_mindex.csv', index_col=['key1', 'key2'])
    >>> parsed
    
                   value1  value2
    key1 key2                
    one  a          1       2
         b          3       4
         c          5       6
         d          7       8
    two  a          9      10
         b         11      12
         c         13      14
         d         15      16



- Parsing Input

    # In some cases, a table may not have a fixed delimiter, for instance using a 
    #   variable amount of whitespace to separate fields.  Regex's can be used
    #   in this case.
    >>> result = pd.read_table('examples/ex3.txt', sep='\s+')


    # The 'skiprows' option can be used to skip rows without data
    >>> pd.read_csv('examples/ex4.csv', skiprows=[0, 2, 3])



- Handling Missing Values

    Missing data is usually either not present (just an empty string) or marked by
      some kind of sentinel value (like 'NA' or 'NULL').

    >>> !cat examples/ex5.csv

    something,a,b,c,d,message
    one,1,2,3,4,NA
    two,5,6,,8,world
    three,9,10,11,12,foo

    >>> result = pd.read_csv('examples/ex5.csv')
    >>> result

      something  a   b     c   d message
    0       one  1   2   3.0   4     NaN
    1       two  5   6   NaN   8   world
    2     three  9  10  11.0  12     foo

    >>> pd.is_null(result)

           something      a      b      c      d  message
    0      False      False  False  False  False     True
    1      False      False  False   True  False    False
    2      False      False  False  False  False    False


    # The 'na_values' option can take either a list or set of strings to consider 
    #   missing values.  (NaN will be inserted in those cells.)
    >>> result = pd.read_csv('examples/ex5.csv', na_values=['NULL'])

    # Different 'na_values' can be specified for each column also
    >>> sentinels = {'message': ['foo', 'NA'], 'something': ['two']}
    >>> pd.read_csv('examples/ex5.csv', na_values=sentinels)



- List of 'read_csv' and 'read_table' Arguments

    Argument	           Description
    ---------------------------------------------------------------------------------------------
    path	               String indicating filesystem location, URL, or file-like object

    sep or delimiter	   Character sequence or regular expression to use to split fields in each row

    header	               Row number to use as column names; defaults to 0 (first row), but should 
                             be None if there is no header row

    index_col	           Column numbers or names to use as the row index in the result; can be a 
                             single name/number or a list of them for a hierarchical index

    names	               List of column names for result, combine with header=None

    skiprows	           Number of rows at beginning of file to ignore or list of row numbers 
                             (starting from 0) to skip.

    na_values	           Sequence of values to replace with NA.

    comment	               Character(s) to split comments off the end of lines.

    parse_dates	           Attempt to parse data to datetime; False by default. If True, will attempt 
                             to parse all columns.  Otherwise can specify a list of column numbers 
                             or name to parse. If element of list is tuple or list, will combine 
                             multiple columns together and parse to date (e.g., if date/time split 
                             across two columns).

    keep_date_col	       If joining columns to parse date, keep the joined columns; False by default.

    converters	           Dict containing column number of name mapping to functions (e.g., {'foo': f} 
                             would apply the function f to all values in the 'foo' column).

    dayfirst	           When parsing potentially ambiguous dates, treat as international format 
                             (e.g., 7/6/2012 -> June 7, 2012); False by default.

    date_parser	           Function to use to parse dates.

    nrows	               Number of rows to read from beginning of file.

    iterator	           Return a TextParser object for reading file piecemeal.

    chunksize	           For iteration, size of file chunks.

    skip_footer	           Number of lines to ignore at end of file.

    verbose	               Print various parser output information, like the number of missing values 
                             placed in non-numeric columns.

    encoding	           Text encoding for Unicode (e.g., 'utf-8' for UTF-8 encoded text).

    squeeze	               If the parsed data only contains one column, return a Series.

    thousands	           Separator for thousands (e.g., ',' or '.').



- Reading Text Files in Pieces


- Writing Data to Text Format


- Working With Delimited Formats


- CSV Dialect Options


- JSON Data


- XML and HTML Scraping


- Parsing XML With LXML.Objectify


- Binary Data Formats


- HDF5


- Reading Excel Files


- Interacting With Web APIs


- Interacting With Databases