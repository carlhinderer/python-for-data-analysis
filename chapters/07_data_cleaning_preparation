------------------------------------------------------
CHAPTER 07 - DATA CLEANING AND PREPARATION
------------------------------------------------------

- Handling Missing Data

    For numeric data, pandas uses the floating point NaN to represent missing data.
      This can be easily detected.

    >>> string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])
    >>> string_data

    0     aardvark
    1    artichoke
    2          NaN
    3      avocado
    dtype: object
    
    >>> string_data.isnull()
    
    0    False
    1    False
    2     True
    3    False
    dtype: bool


    In pandas, we've adopted a convention (used in R) by referring to missing data as
      NA.  This may refer to data that either doesn't exist or wasn't observed.  

    When cleaning up data for analysis, it is important to do analysis on why there is
      missing data in the first place.  Were there data collection problems?  Are there
      potential biases in the data caused by the missing values?


    # The Python value 'None' is also treated as NA in object arrays
    >>> string_data[0] = None
    >>> string_data.isnull()

    0    False
    1    False
    2     True
    3    False
    dtype: bool



- List of NA Handling Methods

    Argument	    Description
    --------------------------------------------------------------------------------
    dropna	        Filter axis labels based on whether values for each label have 
                      missing data, with varying thresholds for how much missing 
                      data to tolerate.

    fillna	        Fill in missing data with some value or using an interpolation 
                      method such as 'ffill' or 'bfill'.

    isnull	        Return boolean values indicating which values are missing/NA.

    notnull	        Negation of isnull.



- Filtering Out Missing Data in Series

    # Using the 'dropna' method on a Series will return only the non-null data 
    #   and index values

    >>> from numpy import nan as NA
    >>> data = pd.Series([1, NA, 3.5, NA, 7])
    >>> data.drop_na()

    0    1.0
    2    3.5
    4    7.0
    dtype: float64

    # This is equivalent
    >>> data[data.notnull()]



- Filtering Out Missing Data in DataFrames

    With DataFrames, things are a bit more complex.  You may want to drop rows or 
      columns that are all NA or those containing any NAs.  By default, 'dropna'
      drops any row containing a missing value.

    >>> data = data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA],
                                    [NA, NA, NA], [NA, 6.5, 3.]])

    >>> cleaned = data.dropna()
    >>> data
         0    1    2
    0  1.0  6.5  3.0
    1  1.0  NaN  NaN
    2  NaN  NaN  NaN
    3  NaN  6.5  3.0

    >>> cleaned
         0    1    2
    0  1.0  6.5  3.0


    # Passing how='all' will only drop rows that are all NA
    >>> data.dropna(how='all')

    # To drop columns that are all NA, use axis=1
    >>> data.dropna(axis=1, how='all')


    # You can also create a threshold where you only keep rows containing a certain 
    #   number of observations.  To drop rows that contain 2 or more NA values:
    >>> df.dropna(thresh=2)



- Filling In Missing Data

    Instead of filtering out missing data, you may want to fill the holes with some
      default value instead.  This is done with the pandas 'fillna' method.

    # Replace all the NA values with a default value
    >>> df.fillna(0)

    # If you pass in a dict, a different value can be used for each column
    >>> df.fillna({1: 0.5, 2: 0})


    # Normally 'fillna' returns a new object.  To modify the existing object in place,
    #   the 'inplace' option is used.
    >>> _ = df.fillna(0, inplace=True)


    # The same interpolation methods available for reindexing can also be used with
    #   'fillna'.  Passing method='ffill' will take the last non-NA value in the 
    #   column and use it to fill in each cell underneath.  Also passing in the 
    #   'limit' option will fill only a specified number of cells.
    >>> df.fillna(method='ffill')
    >>> df.fillna(method='ffill', limit=2)

    # Or maybe you want to just fill in the missing values with the column mean
    >>> data = pd.Series([1., NA, 3.5, NA, 7])
    >>> data.fillna(data.mean())



- List of 'fillna' Arguments

    Argument	Description
    ----------------------------------------------------------------------------
    value	    Scalar value or dict-like object to use to fill missing values

    method	    Interpolation; by default 'ffill' if function called with no other arguments

    axis	    Axis to fill on; default axis=0

    inplace	    Modify the calling object without producing a copy

    limit	    For forward and backward filling, maximum number of consecutive periods to fill



- Removing Duplicates

    Duplicate rows may be found in DataFrames for any number of reasons.

    # Create a DataFrame with a duplicate row
    >>> data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],
                            'k2': [1, 1, 2, 3, 3, 4, 4]})

    >>> data
        k1  k2
    0  one   1
    1  two   1
    2  one   2
    3  two   3
    4  one   3
    5  two   4
    6  two   4

    >>> data.duplicated()
    0    False
    1    False
    2    False
    3    False
    4    False
    5    False
    6     True
    dtype: bool


    # Sometimes, you just want to drop all the duplicates
    >>> data.drop_duplicates()
        k1  k2
    0  one   1
    1  two   1
    2  one   2
    3  two   3
    4  one   3
    5  two   4

    # Or, you can drop duplicates based on a single column's values
    >>> data['v1'] = range(7)
    >>> data.drop_duplicates(['k1'])
        k1  k2  v1
    0  one   1   0
    1  two   1   1


    # By default, 'duplicated' and 'drop_duplicates' will keep the first observed
    #   value combination.  To keep the last one instead, use keep='last'.
    >>> data.drop_duplicates(['k1', 'k2'], keep='last')



- Transforming Data Using a Function or Mapping

    For many datasets, you may wish to perform some transformation based on the 
      values in an array, Series, or column in a DataFrame.

    # Consider the following data collected about various kinds of meat
    >>> data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',
                                      'Pastrami', 'corned beef', 'Bacon',
                                      'pastrami', 'honey ham', 'nova lox'],
                             'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})
    >>> data
     
              food  ounces
    0        bacon     4.0
    1  pulled pork     3.0
    2        bacon    12.0
    3     Pastrami     6.0
    4  corned beef     7.5
    5        Bacon     8.0
    6     pastrami     3.0
    7    honey ham     5.0
    8     nova lox     6.0


    # Now, supposed you wanted to add a column indicating the type of animal that
    #   each food came from.  Here is a mapping for that:
    >>> meat_to_animal = {
         'bacon': 'pig',
         'pulled pork': 'pig',
         'pastrami': 'cow',
         'corned beef': 'cow',
         'honey ham': 'pig',
         'nova lox': 'salmon'
        }


    # One problem we have when matching columns is that some of the foods are
    #   capitalized in data['food'].  So, we'll get a lowercase version of that column.
    >>> lowercased = data['food'].str.lower()

    # Now, we can add the new column
    >>> data['animal'] = lowercased.map(meat_to_animal)


    # Alternatively, we could just pass a function that does all the work
    >>> data['animal'] = data['food'].map(lambda x: meat_to_animal[x.lower()])



- Replacing Values

    Filling in missing data with 'fillna' is actually a special case of the more general
      problem of value replacement.  

    # Create a series
    >>> data = pd.Series([1., -999., 2., -999., -1000., 3.])

    # We may realize that -999 is the sentinel value for missing data
    >>> data.replace(-999, np.nan)
    0       1.0
    1       NaN
    2       2.0
    3       NaN
    4   -1000.0
    5       3.0
    dtype: float64


    # Replace multiple values with a single value
    >>> data.replace([-999, -1000], np.nan)

    # Replace multiple values with a different value for each one
    >>> data.replace([-999, -1000], [np.nan, 0])

    # Or you can pass in a dict instead
    >>> data.replace({-999: np.nan, -1000: 0})



- Renaming Axis Indexes

    Like values in a series, axis labels can also be transformed by a function or mapping
      to produce new, differently-labeled objects.  The axes can also be modified in place
      without creating a new data structure.

    >>> data = pd.DataFrame(np.arange(12).reshape((3, 4)),
                            index=['Ohio', 'Colorado', 'New York'],
                            columns=['one', 'two', 'three', 'four'])


    # Like a Series, the axis indexes have a 'map' method
    >>> transform = lambda x: x[:4].upper()
    >>> data.index.map(transform)

    Index(['OHIO', 'COLO', 'NEW '], dtype='object')


    # You can also assign to index, mofifying the DataFrame in place
    >>> data.index = data.index.map(transform)


    # If you want to create a transformed version of a dataset without modifying the original,
    #   a useful method is 'rename'
    >>> data.rename(index=str.title, columns=str.upper)

          ONE  TWO  THREE  FOUR
    Ohio    0    1      2     3
    Colo    4    5      6     7
    New     8    9     10    11


    # 'rename' can also be used in conjunction with a dict-like object providing new values
    #   for a subset of the axis labels
    >>> data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'})

             one  two  peekaboo  four
    INDIANA    0    1         2     3
    COLO       4    5         6     7
    NEW        8    9        10    11


    # If you want to modify a dataset in place, can just pass 'inplace=True'
    >>> data.rename(index={'OHIO': 'INDIANA'}, inplace=True)



- Discretization and Binning


- Detecting and Filtering Outliers


- Permutation and Random Sampling


- Computing Indicator/Dummy Variables


- Using String Manipulation


- Using Regular Expressions


- List of Regular Expression Methods


- Vectorized String Functions in pandas


- List of Vectorized String Methods