------------------------------------------------------
CHAPTER 07 - DATA CLEANING AND PREPARATION
------------------------------------------------------

- Handling Missing Data

    For numeric data, pandas uses the floating point NaN to represent missing data.
      This can be easily detected.

    >>> string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])
    >>> string_data

    0     aardvark
    1    artichoke
    2          NaN
    3      avocado
    dtype: object
    
    >>> string_data.isnull()
    
    0    False
    1    False
    2     True
    3    False
    dtype: bool


    In pandas, we've adopted a convention (used in R) by referring to missing data as
      NA.  This may refer to data that either doesn't exist or wasn't observed.  

    When cleaning up data for analysis, it is important to do analysis on why there is
      missing data in the first place.  Were there data collection problems?  Are there
      potential biases in the data caused by the missing values?


    # The Python value 'None' is also treated as NA in object arrays
    >>> string_data[0] = None
    >>> string_data.isnull()

    0    False
    1    False
    2     True
    3    False
    dtype: bool



- List of NA Handling Methods

    Argument	    Description
    --------------------------------------------------------------------------------
    dropna	        Filter axis labels based on whether values for each label have 
                      missing data, with varying thresholds for how much missing 
                      data to tolerate.

    fillna	        Fill in missing data with some value or using an interpolation 
                      method such as 'ffill' or 'bfill'.

    isnull	        Return boolean values indicating which values are missing/NA.

    notnull	        Negation of isnull.



- Filtering Out Missing Data in Series

    # Using the 'dropna' method on a Series will return only the non-null data 
    #   and index values

    >>> from numpy import nan as NA
    >>> data = pd.Series([1, NA, 3.5, NA, 7])
    >>> data.drop_na()

    0    1.0
    2    3.5
    4    7.0
    dtype: float64

    # This is equivalent
    >>> data[data.notnull()]



- Filtering Out Missing Data in DataFrames

    With DataFrames, things are a bit more complex.  You may want to drop rows or 
      columns that are all NA or those containing any NAs.  By default, 'dropna'
      drops any row containing a missing value.

    >>> data = data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA],
                                    [NA, NA, NA], [NA, 6.5, 3.]])

    >>> cleaned = data.dropna()
    >>> data
         0    1    2
    0  1.0  6.5  3.0
    1  1.0  NaN  NaN
    2  NaN  NaN  NaN
    3  NaN  6.5  3.0

    >>> cleaned
         0    1    2
    0  1.0  6.5  3.0


    # Passing how='all' will only drop rows that are all NA
    >>> data.dropna(how='all')

    # To drop columns that are all NA, use axis=1
    >>> data.dropna(axis=1, how='all')


    # You can also create a threshold where you only keep rows containing a certain 
    #   number of observations.  To drop rows that contain 2 or more NA values:
    >>> df.dropna(thresh=2)