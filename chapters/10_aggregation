------------------------------------------------------
CHAPTER 10 - DATA AGGREGATION AND GROUP OPERATIONS
------------------------------------------------------

- GroupBy Mechanics

    Hadley Wickham, an author of many popular packages for the R programming language, 
      coined the term 'split-apply-combine' for describing group operations.

      1. Data contained in a pandas object, whether a Series, DataFrame, or otherwise, 
          is split into groups based on one or more keys that you provide. The splitting 
          is performed on a particular axis of an object. For example, a DataFrame can be 
          grouped on its rows (axis=0) or its columns (axis=1). 

      2. Once this is done, a function is applied to each group, producing a new value. 

      3. The results of all those function applications are combined into a result object. 
           The form of the resulting object will usually depend on whatâ€™s being done to the data.


      key  | A   B   C   A   B   C   A   B   C
      data | 0   5  10   5  10  15  10  15  20 
                          |
                          |    SPLIT
                          |
                         \ /

         A   A   A       B   B   B       C   C   C
         0   5  10       5  10  15      10  15  20
                          |
                          |    APPLY
                          |
                         \ /

                         sum()

                          |
                          |    COMBINE
                          |
                         \ /

                      A   B   C
                     15  30  45



- Grouping Keys

    Each grouping key can take many forms, and the keys don't all have to be the same
      type.  Different types of keys include:

      1. A list or array of values the same length as the axis being grouped
      2. A value indicating a column name in a DataFrame
      3. A dict or Series giving a correspondence between the values on the axis being grouped
      4. A function to be invoked on the axis index or the individual labels in the index


    # Create a DataFrame
    >>> df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],
                           'key2' : ['one', 'two', 'one', 'two', 'one'],
                           'data1' : np.random.randn(5),
                           'data2' : np.random.randn(5)})
    >>> df

          data1     data2 key1 key2
    0 -0.204708  1.393406    a  one
    1  0.478943  0.092908    a  two
    2 -0.519439  0.281746    b  one
    3 -0.555730  0.769023    b  two
    4  1.965781  1.246435    a  one


    # Suppose we want to compute the mean of the 'data1' column using the labels from 'key1'
    >>> grouped = df['data1'].groupby(df['key1'])
    >>> grouped
    <pandas.core.groupby.SeriesGroupBy object at 0x7f85008d0400>

    >>> grouped.mean()

    key1
    a    0.746672
    b   -0.537585
    Name: data1, dtype: float64


    # We can also pass multiple arrays as keys
    >>> means = df['data1'].groupby([df['key1'], df['key2']]).mean()
    >>> means

    key1  key2
    a     one     0.880536
          two     0.478943
    b     one    -0.519439
          two    -0.555730
    Name: data1, dtype: float64

    >>> means.unstack()

    key2       one       two
    key1                    
    a     0.880536  0.478943
    b    -0.519439 -0.555730



- Using numpy Arrays as Grouping Keys

    # Create numpy arrays
    >>> states = np.array(['Ohio', 'California', 'California', 'Ohio', 'Ohio'])
    >>> years = np.array([2005, 2005, 2006, 2005, 2006])
    
    # Use numpy arrays as grouping keys
    >>> df['data1'].groupby([states, years]).mean()

    California  2005    0.478943
                2006   -0.519439
    Ohio        2005   -0.380219
                2006    1.965781
    Name: data1, dtype: float64



- Using DataFrame Columns as Grouping Keys

    Frequently, the grouping information is found in the same DataFrame as the data you want
      to work on.  In that case, you can pass column names as group keys.

    >>> df.groupby('key1').mean()

             data1     data2
    key1                    
    a     0.746672  0.910916
    b    -0.537585  0.525384
    
    >>> df.groupby(['key1', 'key2']).mean()
    Out[22]: 
                  data1     data2
    key1 key2                    
    a    one   0.880536  1.319920
         two   0.478943  0.092908
    b    one  -0.519439  0.281746
         two  -0.555730  0.769023


    In the first case above, 'df.groupby('key1').mean()' did not include 'key2' in the
      grouped data.  This is because 'key2' is not numeric data, so it is said to be a
      'nuissance column', and is therefore excluded from the result.



- Getting Group Sizes

    # The 'size' method is used to get group sizes
    >>> df.groupby(['key1', 'key2']).size()

    key1  key2
    a     one     2
          two     1
    b     one     1
          two     1
    dtype: int64



- Iterating Over Groups

    The 'GroupBy' object is iterable, generating a sequence of 2-tuples containing the 
      group name along with the chunk of data.

    >>> for name, group in df.groupby('key1'):
            print(name)
            print(group)

    a
          data1     data2 key1 key2
    0 -0.204708  1.393406    a  one
    1  0.478943  0.092908    a  two
    4  1.965781  1.246435    a  one

    b
          data1     data2 key1 key2
    2 -0.519439  0.281746    b  one
    3 -0.555730  0.769023    b  two


    In the case of multiple keys, the first element in the tuple will be a tuple of key
      values.

    >>> for (k1, k2), group in df.groupby(['key1', 'key2']):
            print((k1, k2))
            print(group)

    ('a', 'one')
          data1     data2 key1 key2
    0 -0.204708  1.393406    a  one
    4  1.965781  1.246435    a  one

    ('a', 'two')
          data1     data2 key1 key2
    1  0.478943  0.092908    a  two

    ('b', 'one')
          data1     data2 key1 key2
    2 -0.519439  0.281746    b  one

    ('b', 'two')
         data1     data2 key1 key2
    3 -0.55573  0.769023    b  two



- Group Iteration Patterns

    # Compute a dict of data pieces as a one-liner
    >>> pieces = dict(list(df.groupby('key1')))
    >>> pieces['b']

          data1     data2 key1 key2
    2 -0.519439  0.281746    b  one
    3 -0.555730  0.769023    b  two


    # Group on object types on column axis
    >>> df.types

    data1    float64
    data2    float64
    key1      object
    key2      object
    dtype: object

    >>> grouped = df.groupby(df.dtypes, axis=1)
    >>> for dtype, group in grouped:
            print(dtype)
            print(group)

    float64
          data1     data2
    0 -0.204708  1.393406
    1  0.478943  0.092908
    2 -0.519439  0.281746
    3 -0.555730  0.769023
    4  1.965781  1.246435

    object
      key1 key2
    0    a  one
    1    a  two
    2    b  one
    3    b  two
    4    a  one



- Selecting a Column or Subset of Columns

    Indexing a GroupBy object created from a DataFrame with a column name or array of
      column names has the effect of column subsetting for aggregation.

    # These are equivalent
    >>> df['data1'].groupby(df['key1'])
    >>> df.groupby('key1')['data1']

    # These are equivalent
    >>> df[['data2']].groupby(df['key1'])
    >>> df.groupby('key1')[['data2']]


    For large datasets, it may be desirable to aggregate only a few columns.

    # Compute means for just the 'data2' column
    >>> df.groupby(['key1', 'key2'])[['data2']].mean()

                  data2
    key1 key2          
    a    one   1.319920
         two   0.092908
    b    one   0.281746
         two   0.769023



- Grouping With Dicts

    Grouping information may exist in a form other than an array.


    # Create a DataFrame and add a few NA values
    >>> people = pd.DataFrame(np.random.randn(5, 5),
                              columns=['a', 'b', 'c', 'd', 'e'],
                              index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])
    >>> people.iloc[2:3, [1, 2]] = np.nan
    >>> people

                   a         b         c         d         e
    Joe     1.007189 -1.296221  0.274992  0.228913  1.352917
    Steve   0.886429 -2.001637 -0.371843  1.669025 -0.438570
    Wes    -0.539741       NaN       NaN -1.021228 -0.577087
    Jim     0.124121  0.302614  0.523772  0.000940  1.343810
    Travis -0.713544 -0.831154 -2.370232 -1.860761 -0.860757


    # Now, supposed we have a group correspondence for the columns and want to sum
    #   together the columns by group.
    >>> mapping = {'a': 'red', 'b': 'red', 'c': 'blue', 'd': 'blue', 'e': 'red', 'f' : 'orange'}


    # We can pass this dict directly to 'groupby'
    >>> by_column = people.groupby(mapping, axis=1)
    >>> by_column.sum()

                blue       red
    Joe     0.503905  1.063885
    Steve   1.297183 -1.553778
    Wes    -1.021228 -1.116829
    Jim     0.524712  1.770545
    Travis -4.230992 -2.405455



- Grouping With Series

    # Create a Series
    >>> map_series = pd.Series(mapping)
    >>> map_series

    a       red
    b       red
    c      blue
    d      blue
    e       red
    f    orange
    dtype: object


    # Grouping by Series works also, since everything gets converted to arrays internally    
    >>> people.groupby(map_series, axis=1).count()

            blue  red
    Joe        2    3
    Steve      2    3
    Wes        1    2
    Jim        2    3
    Travis     2    3



- Grouping With Functions

- Grouping By Index Levels

- Data Aggregations

- List of Optimized groupby Methods

- Column-Wise and Multiple Function Application

- Returning Aggregated Data Without Row Indexes

- Apply: General Split-Apply-Combine

- Suppressing the Group Keys

- Quantile and Bucket Analysis

- Example - Filling Missing Values with Group-Specific Values

- Example - Random Sampling and Permutation

- Example - Group Weighted Average and Correlation

- Example - Group-Wise Linear Regression

- Pivot Tables and Cross-Tabulation

- List of pivot_table Options

- Cross-Tabulations